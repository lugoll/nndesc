Summarize the following Neural Network:

Network: The first layer of the convolutional Neural Network is a Convolutional Layer with 32 filters of the size 7x7 and a ReLU activation function. The second layer is a Convolutional Layer with 64 filters of the size 7x7 and a ReLU activation function. The third layer is a MaxPool Layer for downsampling. The fourth layer is a Convolutional Layer with 128 filters of the size 3x3 and a ReLU activation function. The fifth layer is a Convolutional Layer with 128 filters of the size 3x3 and a ReLU activation function. The sixth layer is a Convolutional Layer with 128 filters of the size 3x3 and a ReLU activation function. The seventh layer is a Convolutional Layer with 128 filters of the size 3x3. The eighth layer is a MaxPool Layer for downsampling. The ninth layer is a Flatten Layer . The last layer is a Dense Layer with 10 output neurons with a Softmax activation function.
Summarization: The Convolutional Neural Network contains several convolutional layers, where the first layers have a kernel size of 7x7 and in the following layers a kernel of 3x3 is used. The number of filters in the convolutional layers increases with increasing layers. A ReLu activation function is used in each layer. For downsampling the data, MaxPool layers are used after some convolutional layers. After a Flatten layer at the end, a fully connected layer with 10 output neurons and a Softmax activation function gives the result.
###
Network: The first layer of the convolutional Neural Network is a Convolutional Layer with 32 filters of the size 3x3 and a ReLU activation function. The second layer is a MaxPool Layer for downsampling. The third layer is a Convolutional Layer with 64 filters of the size 3x3 and a ReLU activation function. The fourth layer is a MaxPool Layer for downsampling. The fifth layer is a Flatten Layer . The last layer is a Dense Layer with 10 output neurons with a Softmax activation function.
Summarization: The convolutional neural network starts with a convolutional layer with a kernel size of 3x3 with 32 filters to which a ReLU is applied as activation function, followed by another convolutional layer with the same kernel size and 64 filters also with a ReLU as activation function. Both convolutional layers are followed by a MaxPool layer for downsampling. Finally, a fully connected layer with a Softmax activation function follows.
###
Network: The first layer of the convolutional Neural Network is a Convolutional Layer with 16 filters of the size 3x3 and a Sigmoid activation function. The second layer is a Convolutional Layer with 16 filters of the size 3x3 and a Sigmoid activation function and the stride of 2. The third layer is a Convolutional Layer with 16 filters of the size 3x3 and a Sigmoid activation function. The fourth layer is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function. The fifth layer is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function and the stride of 2. The sixth layer is a Flatten Layer . The last layer is a Dense Layer with 10 output neurons with a Softmax activation function.
Summarization: The Convolutional Neural Network consists of several convolutional layers, where in each convolutional layer the kernel size 3x3 is used. Sigmoid and ReLU are used as activation function in the hidden layers and a Softmax activation function is used in the output layer, which outputs the results after a single last dense layer. For downsampling, a stride of 2 is used in some convolutional layers.
###
Network: The first layer of the convolutional Neural Network is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function. The second layer is a Convolutional Layer with 32 filters of the size 3x3 and a ReLU activation function. The third layer is a Convolutional Layer with 64 filters of the size 3x3 and a ReLU activation function. The fourth layer is a MaxPool Layer for downsampling. The fifth layer is a Convolutional Layer with 32 filters of the size 3x3 and a ReLU activation function. The sixth layer is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function. The seventh layer is a Convolutional Layer with 16 filters of the size 3x3. The eighth layer is a MaxPool Layer for downsampling. The ninth layer is a Flatten Layer . The last layer is a Dense Layer with 10 output neurons with a Softmax activation function.
Summarization: