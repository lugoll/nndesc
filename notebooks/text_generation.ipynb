{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e55d373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 15:27:17.225951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-31 15:27:17.225972: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import re\n",
    "\n",
    "from generator.loader.onnx_loader import KerasGraphExtractor, PyTorchGraphExtractor\n",
    "from generator.selector.selection import Selector\n",
    "from generator.lexicalizer.template import TemplateEngine\n",
    "from generator.lexicalizer.simple import SimpleLayerLexicalizer\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7996a55e",
   "metadata": {},
   "source": [
    "## The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475a45bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first layer of the convolutional Neural Network is a Convolutional Layer with 32 filters of the size 3x3 and a ReLU activation function. The second layer is a MaxPool Layer for downsampling. The third layer is a Convolutional Layer with 64 filters of the size 3x3 and a ReLU activation function. The fourth layer is a MaxPool Layer for downsampling. The fifth layer is a Flatten Layer . The last layer is a Dense Layer with 10 output neurons with a Softmax activation function.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_onnx_0 = onnx.load('../test/models/pytorch/saved_models/my_cnn.onnx')\n",
    "extractor = PyTorchGraphExtractor(conv_onnx_0)\n",
    "\n",
    "selector = Selector(extractor.graph_structure, property_num=-1)\n",
    "selected_graph_summary = selector.select()\n",
    "\n",
    "text_engine = SimpleLayerLexicalizer(selected_graph_summary)\n",
    "text_cnn_0 = text_engine.render()\n",
    "text_cnn_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd4baa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first layer of the convolutional Neural Network is a Convolutional Layer with 16 filters of the size 3x3 and a Sigmoid activation function. The second layer is a Convolutional Layer with 16 filters of the size 3x3 and a Sigmoid activation function and the stride of 2. The third layer is a Convolutional Layer with 16 filters of the size 3x3 and a Sigmoid activation function. The fourth layer is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function. The fifth layer is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function and the stride of 2. The sixth layer is a Flatten Layer . The last layer is a Dense Layer with 10 output neurons with a Softmax activation function.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_onnx_1 = onnx.load('../test/models/pytorch/saved_models/my_complex_cnn_1.onnx')\n",
    "extractor = PyTorchGraphExtractor(conv_onnx_1)\n",
    "\n",
    "selector = Selector(extractor.graph_structure, property_num=-1)\n",
    "selected_graph_summary = selector.select()\n",
    "\n",
    "text_engine = SimpleLayerLexicalizer(selected_graph_summary)\n",
    "text_cnn_1 = text_engine.render()\n",
    "text_cnn_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6216eea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first layer of the convolutional Neural Network is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function. The second layer is a Convolutional Layer with 32 filters of the size 3x3 and a ReLU activation function. The third layer is a Convolutional Layer with 64 filters of the size 3x3 and a ReLU activation function. The fourth layer is a MaxPool Layer for downsampling. The fifth layer is a Convolutional Layer with 32 filters of the size 3x3 and a ReLU activation function. The sixth layer is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function. The seventh layer is a Convolutional Layer with 16 filters of the size 3x3. The eighth layer is a MaxPool Layer for downsampling. The ninth layer is a Flatten Layer . The last layer is a Dense Layer with 10 output neurons with a Softmax activation function.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_onnx_2 = onnx.load('../test/models/pytorch/saved_models/my_complex_cnn_2.onnx')\n",
    "extractor = PyTorchGraphExtractor(conv_onnx_2)\n",
    "\n",
    "selector = Selector(extractor.graph_structure, property_num=-1)\n",
    "selected_graph_summary = selector.select()\n",
    "\n",
    "text_engine = SimpleLayerLexicalizer(selected_graph_summary)\n",
    "text_cnn_2 = text_engine.render()\n",
    "text_cnn_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d6025f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first layer of the convolutional Neural Network is a Convolutional Layer with 32 filters of the size 7x7 and a ReLU activation function. The second layer is a Convolutional Layer with 64 filters of the size 7x7 and a ReLU activation function. The third layer is a MaxPool Layer for downsampling. The fourth layer is a Convolutional Layer with 128 filters of the size 3x3 and a ReLU activation function. The fifth layer is a Convolutional Layer with 128 filters of the size 3x3 and a ReLU activation function. The sixth layer is a Convolutional Layer with 128 filters of the size 3x3 and a ReLU activation function. The seventh layer is a Convolutional Layer with 128 filters of the size 3x3. The eighth layer is a MaxPool Layer for downsampling. The ninth layer is a Flatten Layer . The last layer is a Dense Layer with 10 output neurons with a Softmax activation function.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_onnx_3 = onnx.load('../test/models/pytorch/saved_models/my_complex_cnn_3.onnx')\n",
    "extractor = PyTorchGraphExtractor(conv_onnx_3)\n",
    "\n",
    "selector = Selector(extractor.graph_structure, property_num=-1)\n",
    "selected_graph_summary = selector.select()\n",
    "\n",
    "text_engine = SimpleLayerLexicalizer(selected_graph_summary)\n",
    "text_cnn_3 = text_engine.render()\n",
    "text_cnn_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee1c79",
   "metadata": {},
   "source": [
    "## Summary Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1323b3d1",
   "metadata": {},
   "source": [
    "### facebook/bart-large-cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cedf8122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=56)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The first layer of the convolutional Neural Network is a Convolutional Layer with 32 filters of the size 3x3 and a ReLU activation function. The second layer is a MaxPool Layer for downsampling. The last layer is an Dense Layer with 10 output neurons with a Softmaxactivation function.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "classifier(text_cnn_0)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b506a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first layer of the convolutional Neural Network is a Convolutional Layer with 16 filters of the size 3x3 and a Sigmoid activation function. The sixth layer is a Flatten Layer . The last layer isA Dense Layer with 10 output neurons with a Softmax activation function and the stride of 2.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassifier = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "classifier(text_cnn_1)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65a45b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First layer of the convolutional Neural Network is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function. Fourth layer is a MaxPool Layer for downsampling. Last layer is Dense Layer with 10 output neurons with a Softmaxactivation function.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "classifier(text_cnn_2)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e87f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first layer of the convolutional Neural Network is a Convolutional Layer with 32 filters of the size 7x7 and a ReLU activation function. The third layer is a MaxPool Layer for downsampling. The last layer is the Dense Layer with 10 output neurons with a Softmaxactivation function.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "classifier(text_cnn_3)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "317d405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 202. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=101)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The sixth layer is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"summarization\", model=\"google/pegasus-large\")\n",
    "classifier(text_cnn_2)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85aafbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a33347970/Workspace/nn-description-gen/venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Scientists have revealed how the layers of the Neural Network are formed.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"summarization\", model=\"csebuetnlp/mT5_multilingual_XLSum\")\n",
    "classifier(text_cnn_2)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4e2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e61b1e98",
   "metadata": {},
   "source": [
    "## Few Shot Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c6129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "API_TOKEN = \"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\"\n",
    "\n",
    "def query(payload='',parameters=None,options={'use_cache': False}):\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/EleutherAI/gpt-j-6B\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "    body = {\"inputs\":payload,'parameters':parameters,'options':options}\n",
    "    response = requests.request(\"POST\", API_URL, headers=headers, data= json.dumps(body))\n",
    "    try:\n",
    "      response.raise_for_status()\n",
    "    except requests.exceptions.HTTPError:\n",
    "        return \"Error:\"+\" \".join(response.json()['error'])\n",
    "    else:\n",
    "      return response.json()[0]['generated_text']\n",
    "\n",
    "parameters = {\n",
    "    'max_new_tokens':250,  # number of generated tokens\n",
    "    'temperature': 0.5,   # controlling the randomness of generations\n",
    "    'end_sequence': \"###\" # stopping sequence for generation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683515de",
   "metadata": {},
   "source": [
    "The example networks mnist_complex_conv_net_1 and mnist_complex_conv_net_3 are used as few-shot examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0943797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Summarize the following Neural Network:\n",
    "\n",
    "Network: The first layer of the convolutional Neural Network is a Convolutional Layer with 32 filters of the size 7x7 and a ReLU activation function. The second layer is a Convolutional Layer with 64 filters of the size 7x7 and a ReLU activation function. The third layer is a MaxPool Layer for downsampling. The fourth layer is a Convolutional Layer with 128 filters of the size 3x3 and a ReLU activation function. The fifth layer is a Convolutional Layer with 128 filters of the size 3x3 and a ReLU activation function. The sixth layer is a Convolutional Layer with 128 filters of the size 3x3 and a ReLU activation function. The seventh layer is a Convolutional Layer with 128 filters of the size 3x3. The eighth layer is a MaxPool Layer for downsampling. The ninth layer is a Flatten Layer . The last layer is a Dense Layer with 10 output neurons with a Softmax activation function.\n",
    "Summarization: The Convolutional Neural Network contains several convolutional layers, where the first layers have a kernel size of 7x7 and in the following layers a kernel of 3x3 is used. The number of filters in the convolutional layers increases with increasing layers. A ReLu activation function is used in each layer. For downsampling the data, MaxPool layers are used after some convolutional layers. After a Flatten layer at the end, a fully connected layer with 10 output neurons and a Softmax activation function gives the result.\n",
    "###\n",
    "Network: The first layer of the convolutional Neural Network is a Convolutional Layer with 16 filters of the size 3x3 and a Sigmoid activation function. The second layer is a Convolutional Layer with 16 filters of the size 3x3 and a Sigmoid activation function and the stride of 2. The third layer is a Convolutional Layer with 16 filters of the size 3x3 and a Sigmoid activation function. The fourth layer is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function. The fifth layer is a Convolutional Layer with 16 filters of the size 3x3 and a ReLU activation function and the stride of 2. The sixth layer is a Flatten Layer . The last layer is a Dense Layer with 10 output neurons with a Softmax activation function.\n",
    "Summarization: The Convolutional Neural Network consists of several convolutional layers, where in each convolutional layer the kernel size 3x3 is used. Sigmoid and ReLU are used as activation function in the hidden layers and a Softmax activation function is used in the output layer, which outputs the results after a single last dense layer. For downsampling, a stride of 2 is used in some convolutional layers.\n",
    "###\n",
    "Network: {simple_desc}\n",
    "Summarization:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f8539",
   "metadata": {},
   "source": [
    "### Test on My Complex CNN 2 on Huggingface Inference API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6f0cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cnn_2 = prompt.format(simple_desc=text_cnn_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c813b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = query(prompt_cnn_2,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e87a6eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Convolutional Neural Network contains several convolutional layers, where the first layers have a kernel size of 3x3 and in the following layers a kernel of 3x3 is used. The number of filters in the convolutional layers increases with increasing layers. A ReLU activation function is used in each layer. For downsampling the data, MaxPool layers are used after some convolutional layers. After a Flatten layer at the end, a fully connected layer with 10 output neurons and a Softmax activation function gives the result.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.split('\\n')[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be06d4",
   "metadata": {},
   "source": [
    "### Test on My CNN on Huggingface Inference API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9db61802",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cnn_0 = prompt.format(simple_desc=text_cnn_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "440cb91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = query(prompt_cnn_0,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29548720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Convolutional Neural Network consists of several convolutional layers, where in each convolutional layer the kernel size 3x3 is used. A ReLU activation function is used in the hidden layers and a Softmax activation function is used in the output layer, which outputs the results after a single last dense layer. For downsampling, a stride of 2 is used in some convolutional layers.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0.split('\\n')[-2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
